{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import wordpunct_tokenize\n",
    "import goslate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides stopwords of different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'arabic', u'azerbaijani', u'danish', u'dutch', u'english', u'finnish', u'french', u'german', u'greek', u'hungarian', u'indonesian', u'italian', u'kazakh', u'nepali', u'norwegian', u'portuguese', u'romanian', u'russian', u'spanish', u'swedish', u'turkish']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = []\n",
    "[(langs.append(lang)) for lang in stopwords.fileids()]\n",
    "\n",
    "#Lets see the languages supported by nltk\n",
    "print (langs)\n",
    "\n",
    "# Have a look at the number of different languages provided.\n",
    "len(langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate_lang_ratios() returns a dictionary which contains different languages as keys and corresponding to which we have value as the number of common stopwords of that language and the input text words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lang_ratios(text):\n",
    "    lang_ratios = {}\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    \n",
    "    # Convert tokens into lower case so as to match easily.\n",
    "    words = [word.lower() for word in tokens]\n",
    "    \n",
    "    for language in stopwords.fileids():\n",
    "        \n",
    "        # 'set' functions returns unique values from the list\n",
    "        set_stopwords = set(stopwords.words(language))\n",
    "        set_words = set(words)\n",
    "        \n",
    "        # Extracting common words for each language.\n",
    "        common_words = set_words.intersection(set_stopwords)\n",
    "        \n",
    "        lang_ratios[language] = len(common_words)\n",
    "    return lang_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify_lang() function returns one language having most number of common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_lang(text):\n",
    "    get_ratio = calculate_lang_ratios(text)\n",
    "    \n",
    "    # 'get' function returns value for the key.\n",
    "    most_rated_lang = max(get_ratio, key=get_ratio.get)\n",
    "    return most_rated_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the code by taking text of different languages and see how the code works !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to be identified: \n",
      "Im Moment gibt es noch ein großes Durcheinander im Haus, viele Kartons sind noch nicht ausgepackt, aber das wird sich bald ändern. Wir sind alle sehr froh\n",
      "\n",
      "Language Identified : german\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = raw_input(\"Enter text to be identified: \\n\")\n",
    "lang_identified = identify_lang(input_text)\n",
    "print '\\nLanguage Identified : ' + lang_identified + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of text to different language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Google Translate API. Apart from translation, it supports language detection, batch translation, dictionary lookup and more.\n",
    "The goslate module connects with the Google Translate API.\n",
    "The first step is to install the goslate module.\n",
    "Install goslate using pyenv, pipenv or virtualenv.\n",
    "#> pip install goslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The goslate module connects with the Google Translate API.\n",
    "gs = goslate.Goslate()\n",
    "translated_lang = gs.translate(input_text,'en')\n",
    "#print \"Translated Language :\" + translated_lang +'\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
